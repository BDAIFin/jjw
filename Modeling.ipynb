{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "ZIP_ONLINE = \"online_data-20260209T062301Z-1-001.zip\"\n",
        "EXTRACT_DIR = \"online_data_unzipped\"   # 새로 푼 폴더(기존 것과 섞이지 않게)\n",
        "LABEL = \"fraud\"\n",
        "\n",
        "# 운영 정책\n",
        "TARGET_RECALL = 0.70\n",
        "RANDOM_SEED = 42"
      ],
      "metadata": {
        "id": "0DCpCpSdfR1h"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, shutil, re\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def unzip(zip_path: str, out_dir: str):\n",
        "    assert os.path.exists(zip_path), f\"zip not found: {zip_path}\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(out_dir)\n",
        "\n",
        "def find_dataset_paths(root_dir: str):\n",
        "    \"\"\"\n",
        "    zip 내부 구조를 전혀 가정하지 않고, 파일명/경로에 train/test/check가 포함된 '파일'을 찾는다.\n",
        "    - 확장자 없어도 OK\n",
        "    - parquet/arrow/기타여도 일단 후보 수집\n",
        "    \"\"\"\n",
        "    root = Path(root_dir)\n",
        "    files = [p for p in root.rglob(\"*\") if p.is_file()]\n",
        "    if not files:\n",
        "        raise RuntimeError(\"No files found after unzip.\")\n",
        "\n",
        "    def pick_one(keyword: str):\n",
        "        cands = []\n",
        "        for p in files:\n",
        "            s = str(p).lower()\n",
        "            # 디렉토리명/파일명 어디든 train/test/check가 들어가면 후보\n",
        "            if re.search(rf\"\\b{keyword}\\b\", s) or f\"/{keyword}\" in s or f\"_{keyword}\" in s:\n",
        "                cands.append(p)\n",
        "        # 가장 '파일 크기 큰' 후보를 우선 선택(보통 진짜 데이터)\n",
        "        cands = sorted(cands, key=lambda x: x.stat().st_size, reverse=True)\n",
        "        return cands[0] if cands else None\n",
        "\n",
        "    train_p = pick_one(\"train\")\n",
        "    test_p  = pick_one(\"test\")\n",
        "    check_p = pick_one(\"check\") or pick_one(\"val\") or pick_one(\"valid\")\n",
        "\n",
        "    if train_p is None or test_p is None:\n",
        "        # 디버깅 정보 제공(근거 로그)\n",
        "        sample = \"\\n\".join([str(p) for p in files[:40]])\n",
        "        raise RuntimeError(\n",
        "            \"Could not locate train/test files automatically.\\n\"\n",
        "            f\"Found {len(files)} files. First 40:\\n{sample}\"\n",
        "        )\n",
        "\n",
        "    return str(train_p), str(test_p), (str(check_p) if check_p else None)\n",
        "\n",
        "# 실행\n",
        "# (기존에 풀어둔 폴더가 있더라도, 혼선 방지 위해 새 폴더에 풀어버림)\n",
        "if os.path.exists(EXTRACT_DIR):\n",
        "    shutil.rmtree(EXTRACT_DIR)\n",
        "\n",
        "unzip(ZIP_ONLINE, EXTRACT_DIR)\n",
        "train_path, test_path, check_path = find_dataset_paths(EXTRACT_DIR)\n",
        "\n",
        "print(\"Picked paths:\")\n",
        "print(\" train:\", train_path)\n",
        "print(\" test :\", test_path)\n",
        "print(\" check:\", check_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKDGpvhafUWb",
        "outputId": "e31145eb-0c68-4e7b-b2a5-b5e297636faf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Picked paths:\n",
            " train: online_data_unzipped/online_data/train\n",
            " test : online_data_unzipped/online_data/test\n",
            " check: online_data_unzipped/online_data/check\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_parquet_flexible(path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    - path가 확장자 없어서 pd.read_parquet가 실패하는 경우가 있어, 임시로 .parquet 복사본 만들어 재시도\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return pd.read_parquet(path)\n",
        "    except Exception:\n",
        "        tmp = path + \".parquet\"\n",
        "        if not os.path.exists(tmp):\n",
        "            shutil.copy(path, tmp)\n",
        "        return pd.read_parquet(tmp)\n",
        "\n",
        "df_train = read_parquet_flexible(train_path)\n",
        "df_test  = read_parquet_flexible(test_path)\n",
        "df_check = read_parquet_flexible(check_path) if check_path else None\n",
        "\n",
        "print(\"Shapes:\", df_train.shape, df_test.shape, None if df_check is None else df_check.shape)\n",
        "assert LABEL in df_train.columns and LABEL in df_test.columns, f\"Missing label '{LABEL}'\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHnsJLiafWqx",
        "outputId": "482688be-3f31-4e8a-b5ec-99fb97d0aca4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (609655, 60) (114209, 60) (166904, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_report(df: pd.DataFrame, name: str):\n",
        "    y = df[LABEL].astype(int)\n",
        "    return {\n",
        "        \"split\": name,\n",
        "        \"rows\": int(df.shape[0]),\n",
        "        \"cols\": int(df.shape[1]),\n",
        "        \"pos_cnt\": int(y.sum()),\n",
        "        \"pos_rate\": float(y.mean()),\n",
        "    }\n",
        "\n",
        "rep = [split_report(df_train, \"train\"), split_report(df_test, \"test\")]\n",
        "if df_check is not None:\n",
        "    rep.append(split_report(df_check, \"check\"))\n",
        "display(pd.DataFrame(rep))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "6Bu83FsCfYwT",
        "outputId": "8388bfa4-5d15-458e-de76-8b6f7521b2c3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   split    rows  cols  pos_cnt  pos_rate\n",
              "0  train  609655    60     6598  0.010823\n",
              "1   test  114209    60     2096  0.018352\n",
              "2  check  166904    60        0  0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-742a11fe-f9c4-42e5-bc26-30a8ffee8ec9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split</th>\n",
              "      <th>rows</th>\n",
              "      <th>cols</th>\n",
              "      <th>pos_cnt</th>\n",
              "      <th>pos_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train</td>\n",
              "      <td>609655</td>\n",
              "      <td>60</td>\n",
              "      <td>6598</td>\n",
              "      <td>0.010823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test</td>\n",
              "      <td>114209</td>\n",
              "      <td>60</td>\n",
              "      <td>2096</td>\n",
              "      <td>0.018352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>check</td>\n",
              "      <td>166904</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-742a11fe-f9c4-42e5-bc26-30a8ffee8ec9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-742a11fe-f9c4-42e5-bc26-30a8ffee8ec9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-742a11fe-f9c4-42e5-bc26-30a8ffee8ec9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\",\n          \"test\",\n          \"check\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rows\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 272112,\n        \"min\": 114209,\n        \"max\": 609655,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          609655,\n          114209,\n          166904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cols\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 60,\n        \"max\": 60,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_cnt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3371,\n        \"min\": 0,\n        \"max\": 6598,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6598\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00922525869056841,\n        \"min\": 0.0,\n        \"max\": 0.018352318994124806,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.010822514372883023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DROP_IF_EXISTS = [\n",
        "    \"client_id\", \"card_id\", \"transaction_id\", \"id\",  # 흔한 키\n",
        "]\n",
        "\n",
        "def normalize_schema(train: pd.DataFrame, test: pd.DataFrame, check: pd.DataFrame | None):\n",
        "    \"\"\"\n",
        "    1) 공통 컬럼만 사용 (버전 차이/누락 방지)\n",
        "    2) label 보존\n",
        "    \"\"\"\n",
        "    cols = set(train.columns) & set(test.columns)\n",
        "    if check is not None:\n",
        "        cols = cols & set(check.columns)\n",
        "    cols = sorted(cols)\n",
        "\n",
        "    train2 = train[cols].copy()\n",
        "    test2  = test[cols].copy()\n",
        "    check2 = check[cols].copy() if check is not None else None\n",
        "    return train2, test2, check2\n",
        "\n",
        "df_train2, df_test2, df_check2 = normalize_schema(df_train, df_test, df_check)\n",
        "\n",
        "def separate_xy(df: pd.DataFrame):\n",
        "    y = df[LABEL].astype(int).values\n",
        "    X = df.drop(columns=[LABEL], errors=\"ignore\").copy()\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = separate_xy(df_train2)\n",
        "X_test,  y_test  = separate_xy(df_test2)\n",
        "X_check, y_check = (separate_xy(df_check2) if df_check2 is not None else (None, None))\n",
        "\n",
        "# ID/키 컬럼 제거(있으면)\n",
        "for c in DROP_IF_EXISTS:\n",
        "    if c in X_train.columns:\n",
        "        X_train.drop(columns=[c], inplace=True)\n",
        "        X_test.drop(columns=[c], inplace=True)\n",
        "        if X_check is not None:\n",
        "            X_check.drop(columns=[c], inplace=True)\n",
        "\n",
        "# datetime 컬럼 자동 제거(있으면)\n",
        "dt_cols = list(X_train.select_dtypes(include=[\"datetime64[ns]\", \"datetime64[ns, UTC]\"]).columns)\n",
        "if dt_cols:\n",
        "    X_train.drop(columns=dt_cols, inplace=True, errors=\"ignore\")\n",
        "    X_test.drop(columns=dt_cols, inplace=True, errors=\"ignore\")\n",
        "    if X_check is not None:\n",
        "        X_check.drop(columns=dt_cols, inplace=True, errors=\"ignore\")\n",
        "\n",
        "# object 중 \"숫자처럼 생긴 문자열\"은 numeric으로 강제 변환\n",
        "def coerce_object_to_numeric(df: pd.DataFrame):\n",
        "    obj_cols = list(df.select_dtypes(include=[\"object\"]).columns)\n",
        "    for c in obj_cols:\n",
        "        # 변환 시도\n",
        "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "        # 숫자화 성공 비율이 충분히 높으면 numeric으로 전환\n",
        "        ok_ratio = s.notna().mean()\n",
        "        if ok_ratio >= 0.95:   # 기준은 보수적으로\n",
        "            df[c] = s\n",
        "    return df\n",
        "\n",
        "X_train = coerce_object_to_numeric(X_train)\n",
        "X_test  = coerce_object_to_numeric(X_test)\n",
        "if X_check is not None:\n",
        "    X_check = coerce_object_to_numeric(X_check)\n",
        "\n",
        "# 최종 공통 컬럼 재강제(위 드랍으로 차이 생기면 방지)\n",
        "common_cols = sorted(set(X_train.columns) & set(X_test.columns) & (set(X_check.columns) if X_check is not None else set(X_train.columns)))\n",
        "X_train = X_train[common_cols]\n",
        "X_test  = X_test[common_cols]\n",
        "if X_check is not None:\n",
        "    X_check = X_check[common_cols]\n",
        "\n",
        "print(\"Final feature cols:\", len(common_cols))\n",
        "print(\"Datetime dropped:\", dt_cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTolQNLJfdhf",
        "outputId": "63e39923-9bba-4ff5-98d4-0fcf4183e22b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature cols: 56\n",
            "Datetime dropped: ['date']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def build_preprocess(X: pd.DataFrame):\n",
        "    num_cols = list(X.select_dtypes(include=[\"number\", \"bool\"]).columns)\n",
        "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "\n",
        "    numeric_tf = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    ])\n",
        "\n",
        "    categorical_tf = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)),\n",
        "    ])\n",
        "\n",
        "    preprocess = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_tf, num_cols),\n",
        "            (\"cat\", categorical_tf, cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    return preprocess, num_cols, cat_cols\n",
        "\n",
        "preprocess, num_cols, cat_cols = build_preprocess(X_train)\n",
        "print(\"Numeric:\", len(num_cols), \"Categorical:\", len(cat_cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-6f6DqZfetQ",
        "outputId": "68158f6f-2741-4b6a-8090-885c762fa9dc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric: 56 Categorical: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "def build_models(preprocess):\n",
        "    models = {}\n",
        "\n",
        "    # 1) 팀원 baseline 핵심: cost-sensitive logistic\n",
        "    models[\"logit_l2_balanced\"] = Pipeline([\n",
        "        (\"prep\", preprocess),\n",
        "        (\"scaler\", StandardScaler(with_mean=False)),  # sparse 대응\n",
        "        (\"clf\", LogisticRegression(max_iter=500, n_jobs=-1, class_weight=\"balanced\"))\n",
        "    ])\n",
        "\n",
        "    # 2) HGB: 빠르고 강력한 비선형 기준점\n",
        "    models[\"hgb\"] = Pipeline([\n",
        "        (\"prep\", preprocess),\n",
        "        (\"clf\", HistGradientBoostingClassifier(random_state=RANDOM_SEED))\n",
        "    ])\n",
        "\n",
        "    # 3) Linear SVM + Calibration: 선형 경계 + 확률 (운영형 threshold에 유리)\n",
        "    base_svm = Pipeline([\n",
        "        (\"prep\", preprocess),\n",
        "        (\"scaler\", StandardScaler(with_mean=False)),\n",
        "        (\"svc\", LinearSVC(class_weight=\"balanced\", random_state=RANDOM_SEED))\n",
        "    ])\n",
        "    models[\"linear_svm_calibrated\"] = CalibratedClassifierCV(base_svm, method=\"sigmoid\", cv=3)\n",
        "\n",
        "    # 4~5) LGBM/XGB는 설치돼 있을 때만 추가(없으면 자동 제외)\n",
        "    try:\n",
        "        from lightgbm import LGBMClassifier\n",
        "        models[\"lgbm\"] = Pipeline([\n",
        "            (\"prep\", preprocess),\n",
        "            (\"clf\", LGBMClassifier(\n",
        "                n_estimators=800, num_leaves=63, learning_rate=0.05,\n",
        "                subsample=0.8, colsample_bytree=0.8,\n",
        "                n_jobs=-1, random_state=RANDOM_SEED,\n",
        "                objective=\"binary\", class_weight=\"balanced\"\n",
        "            ))\n",
        "        ])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        from xgboost import XGBClassifier\n",
        "        spw = (y_train==0).sum() / max((y_train==1).sum(), 1)\n",
        "        models[\"xgb\"] = Pipeline([\n",
        "            (\"prep\", preprocess),\n",
        "            (\"clf\", XGBClassifier(\n",
        "                n_estimators=600, max_depth=6, learning_rate=0.05,\n",
        "                subsample=0.8, colsample_bytree=0.8,\n",
        "                tree_method=\"hist\", n_jobs=-1, random_state=RANDOM_SEED,\n",
        "                objective=\"binary:logistic\", eval_metric=\"aucpr\",\n",
        "                scale_pos_weight=spw\n",
        "            ))\n",
        "        ])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return models\n",
        "\n",
        "models = build_models(preprocess)\n",
        "print(\"Models:\", list(models.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE7ZOgCDfg-z",
        "outputId": "9e106f40-79fc-4c6a-867c-f5103304119b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models: ['logit_l2_balanced', 'hgb', 'linear_svm_calibrated', 'lgbm', 'xgb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score, roc_auc_score, precision_recall_curve, confusion_matrix\n",
        "\n",
        "def score_proba_or_margin(model, X):\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        return model.predict_proba(X)[:, 1]\n",
        "    if hasattr(model, \"decision_function\"):\n",
        "        raw = model.decision_function(X)\n",
        "        # margin을 [0,1]로 정규화(확률은 아니지만 threshold sweep엔 충분)\n",
        "        return (raw - raw.min()) / (raw.max() - raw.min() + 1e-12)\n",
        "    raise RuntimeError(\"Model has neither predict_proba nor decision_function\")\n",
        "\n",
        "def choose_threshold_under_recall(y_true, y_score, target_recall=0.70):\n",
        "    precision, recall, thr = precision_recall_curve(y_true, y_score)\n",
        "    # precision_recall_curve는 thr 길이가 하나 짧음\n",
        "    p, r, t = precision[1:], recall[1:], thr\n",
        "\n",
        "    ok = r >= target_recall\n",
        "    if not np.any(ok):\n",
        "        i = int(np.argmax(r))\n",
        "        return float(t[i]), float(p[i]), float(r[i]), \"target_recall_not_met\"\n",
        "\n",
        "    cand = np.where(ok)[0]\n",
        "    best_p = np.max(p[cand])\n",
        "    bests = cand[p[cand] == best_p]\n",
        "    i = int(bests[np.argmax(t[bests])])  # 같은 precision이면 threshold 큰 것(=경보량↓)\n",
        "    return float(t[i]), float(p[i]), float(r[i]), \"picked_best_precision_under_recall\"\n",
        "\n",
        "def ops_at_threshold(y_true, y_score, thr):\n",
        "    y_hat = (y_score >= thr).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
        "    prec = tp / (tp + fp + 1e-12)\n",
        "    rec  = tp / (tp + fn + 1e-12)\n",
        "    return {\n",
        "        \"precision\": float(prec),\n",
        "        \"recall\": float(rec),\n",
        "        \"alert_rate\": float(y_hat.mean()),\n",
        "        \"tp\": int(tp), \"fp\": int(fp), \"fn\": int(fn), \"tn\": int(tn)\n",
        "    }\n",
        "\n",
        "results = []\n",
        "run_log = {\n",
        "    \"data_paths\": {\"train\": train_path, \"test\": test_path, \"check\": check_path},\n",
        "    \"policy\": {\"target_recall\": TARGET_RECALL},\n",
        "    \"feature_policy\": {\n",
        "        \"dropped_ids\": [c for c in DROP_IF_EXISTS if c in df_train.columns],\n",
        "        \"dropped_datetime_cols\": dt_cols,\n",
        "        \"final_feature_count\": len(common_cols),\n",
        "        \"numeric_count\": len(num_cols),\n",
        "        \"categorical_count\": len(cat_cols),\n",
        "    }\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    s_test = score_proba_or_margin(model, X_test)\n",
        "    test_pr  = float(average_precision_score(y_test, s_test))\n",
        "    test_roc = float(roc_auc_score(y_test, s_test))\n",
        "\n",
        "    thr, thr_p, thr_r, note = choose_threshold_under_recall(y_test, s_test, TARGET_RECALL)\n",
        "    test_ops = ops_at_threshold(y_test, s_test, thr)\n",
        "\n",
        "    # check는 운영 시뮬레이션(양성이 0개일 수 있음 -> 그 자체가 중요한 사실)\n",
        "    check_ops = None\n",
        "    check_pos = None\n",
        "    if X_check is not None:\n",
        "        s_check = score_proba_or_margin(model, X_check)\n",
        "        check_pos = int(np.sum(y_check == 1))\n",
        "        # check에 양성이 0개면 recall/PR은 해석 불가 -> alert_rate 중심으로 모니터링\n",
        "        check_ops = ops_at_threshold(y_check, s_check, thr)\n",
        "\n",
        "    print(f\"TEST  PR-AUC={test_pr:.4f} ROC-AUC={test_roc:.4f} | thr={thr:.6f} ({note})\")\n",
        "    print(\"TEST  ops:\", test_ops)\n",
        "    if check_ops is not None:\n",
        "        print(\"CHECK ops:\", check_ops, \"| check_pos:\", check_pos)\n",
        "\n",
        "    results.append({\n",
        "        \"model\": name,\n",
        "        \"test_pr_auc\": test_pr,\n",
        "        \"test_roc_auc\": test_roc,\n",
        "        \"thr\": thr,\n",
        "        \"test_precision@thr\": test_ops[\"precision\"],\n",
        "        \"test_recall@thr\": test_ops[\"recall\"],\n",
        "        \"test_alert_rate@thr\": test_ops[\"alert_rate\"],\n",
        "        \"test_fp\": test_ops[\"fp\"],\n",
        "        \"test_fn\": test_ops[\"fn\"],\n",
        "        \"check_alert_rate@thr\": (check_ops[\"alert_rate\"] if check_ops is not None else np.nan),\n",
        "        \"check_pos_cnt\": (check_pos if check_pos is not None else np.nan),\n",
        "    })\n",
        "\n",
        "summary = pd.DataFrame(results).sort_values(\n",
        "    [\"test_pr_auc\", \"test_precision@thr\"], ascending=False\n",
        ").reset_index(drop=True)\n",
        "\n",
        "display(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "MhN4f1kUflk7",
        "outputId": "cf0f57c5-282b-4415-ced8-9c9f7d6e8fa8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== logit_l2_balanced ===\n",
            "TEST  PR-AUC=0.2382 ROC-AUC=0.8819 | thr=0.664233 (picked_best_precision_under_recall)\n",
            "TEST  ops: {'precision': 0.10558872185859165, 'recall': 0.7003816793893127, 'alert_rate': 0.12173296325158263, 'tp': 1468, 'fp': 12435, 'fn': 628, 'tn': 99678}\n",
            "CHECK ops: {'precision': 0.0, 'recall': 0.0, 'alert_rate': 0.11002732109476106, 'tp': 0, 'fp': 18364, 'fn': 0, 'tn': 148540} | check_pos: 0\n",
            "\n",
            "=== hgb ===\n",
            "TEST  PR-AUC=0.8715 ROC-AUC=0.9855 | thr=0.679801 (picked_best_precision_under_recall)\n",
            "TEST  ops: {'precision': 0.9780292942743003, 'recall': 0.7008587786259539, 'alert_rate': 0.013151327828805086, 'tp': 1469, 'fp': 33, 'fn': 627, 'tn': 112080}\n",
            "CHECK ops: {'precision': 0.0, 'recall': 0.0, 'alert_rate': 0.00034151368451325315, 'tp': 0, 'fp': 57, 'fn': 0, 'tn': 166847} | check_pos: 0\n",
            "\n",
            "=== linear_svm_calibrated ===\n",
            "TEST  PR-AUC=0.2029 ROC-AUC=0.8837 | thr=0.025359 (picked_best_precision_under_recall)\n",
            "TEST  ops: {'precision': 0.1065032987747408, 'recall': 0.7008587786259539, 'alert_rate': 0.12076981673948638, 'tp': 1469, 'fp': 12324, 'fn': 627, 'tn': 99789}\n",
            "CHECK ops: {'precision': 0.0, 'recall': 0.0, 'alert_rate': 0.10863730048411063, 'tp': 0, 'fp': 18132, 'fn': 0, 'tn': 148772} | check_pos: 0\n",
            "\n",
            "=== lgbm ===\n",
            "[LightGBM] [Info] Number of positive: 6598, number of negative: 603057\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.244309 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4047\n",
            "[LightGBM] [Info] Number of data points in the train set: 609655, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST  PR-AUC=0.9102 ROC-AUC=0.9896 | thr=0.924202 (picked_best_precision_under_recall)\n",
            "TEST  ops: {'precision': 0.9945799457994574, 'recall': 0.7003816793893127, 'alert_rate': 0.012923675016855063, 'tp': 1468, 'fp': 8, 'fn': 628, 'tn': 112105}\n",
            "CHECK ops: {'precision': 0.0, 'recall': 0.0, 'alert_rate': 2.3965872597421273e-05, 'tp': 0, 'fp': 4, 'fn': 0, 'tn': 166900} | check_pos: 0\n",
            "\n",
            "=== xgb ===\n",
            "TEST  PR-AUC=0.8582 ROC-AUC=0.9868 | thr=0.850684 (picked_best_precision_under_recall)\n",
            "TEST  ops: {'precision': 0.9130974549968959, 'recall': 0.7018129770992363, 'alert_rate': 0.014105718463518636, 'tp': 1471, 'fp': 140, 'fn': 625, 'tn': 111973}\n",
            "CHECK ops: {'precision': 0.0, 'recall': 0.0, 'alert_rate': 0.0007549249868187701, 'tp': 0, 'fp': 126, 'fn': 0, 'tn': 166778} | check_pos: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   model  test_pr_auc  test_roc_auc       thr  \\\n",
              "0                   lgbm     0.910221      0.989567  0.924202   \n",
              "1                    hgb     0.871526      0.985462  0.679801   \n",
              "2                    xgb     0.858233      0.986790  0.850684   \n",
              "3      logit_l2_balanced     0.238226      0.881921  0.664233   \n",
              "4  linear_svm_calibrated     0.202855      0.883685  0.025359   \n",
              "\n",
              "   test_precision@thr  test_recall@thr  test_alert_rate@thr  test_fp  test_fn  \\\n",
              "0            0.994580         0.700382             0.012924        8      628   \n",
              "1            0.978029         0.700859             0.013151       33      627   \n",
              "2            0.913097         0.701813             0.014106      140      625   \n",
              "3            0.105589         0.700382             0.121733    12435      628   \n",
              "4            0.106503         0.700859             0.120770    12324      627   \n",
              "\n",
              "   check_alert_rate@thr  check_pos_cnt  \n",
              "0              0.000024              0  \n",
              "1              0.000342              0  \n",
              "2              0.000755              0  \n",
              "3              0.110027              0  \n",
              "4              0.108637              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db855782-41f6-4df3-8a36-7376d195318d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>test_pr_auc</th>\n",
              "      <th>test_roc_auc</th>\n",
              "      <th>thr</th>\n",
              "      <th>test_precision@thr</th>\n",
              "      <th>test_recall@thr</th>\n",
              "      <th>test_alert_rate@thr</th>\n",
              "      <th>test_fp</th>\n",
              "      <th>test_fn</th>\n",
              "      <th>check_alert_rate@thr</th>\n",
              "      <th>check_pos_cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lgbm</td>\n",
              "      <td>0.910221</td>\n",
              "      <td>0.989567</td>\n",
              "      <td>0.924202</td>\n",
              "      <td>0.994580</td>\n",
              "      <td>0.700382</td>\n",
              "      <td>0.012924</td>\n",
              "      <td>8</td>\n",
              "      <td>628</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hgb</td>\n",
              "      <td>0.871526</td>\n",
              "      <td>0.985462</td>\n",
              "      <td>0.679801</td>\n",
              "      <td>0.978029</td>\n",
              "      <td>0.700859</td>\n",
              "      <td>0.013151</td>\n",
              "      <td>33</td>\n",
              "      <td>627</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xgb</td>\n",
              "      <td>0.858233</td>\n",
              "      <td>0.986790</td>\n",
              "      <td>0.850684</td>\n",
              "      <td>0.913097</td>\n",
              "      <td>0.701813</td>\n",
              "      <td>0.014106</td>\n",
              "      <td>140</td>\n",
              "      <td>625</td>\n",
              "      <td>0.000755</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>logit_l2_balanced</td>\n",
              "      <td>0.238226</td>\n",
              "      <td>0.881921</td>\n",
              "      <td>0.664233</td>\n",
              "      <td>0.105589</td>\n",
              "      <td>0.700382</td>\n",
              "      <td>0.121733</td>\n",
              "      <td>12435</td>\n",
              "      <td>628</td>\n",
              "      <td>0.110027</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>linear_svm_calibrated</td>\n",
              "      <td>0.202855</td>\n",
              "      <td>0.883685</td>\n",
              "      <td>0.025359</td>\n",
              "      <td>0.106503</td>\n",
              "      <td>0.700859</td>\n",
              "      <td>0.120770</td>\n",
              "      <td>12324</td>\n",
              "      <td>627</td>\n",
              "      <td>0.108637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db855782-41f6-4df3-8a36-7376d195318d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db855782-41f6-4df3-8a36-7376d195318d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db855782-41f6-4df3-8a36-7376d195318d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_bd293e5b-64c2-48dc-a48b-261f83b530b2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bd293e5b-64c2-48dc-a48b-261f83b530b2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary",
              "summary": "{\n  \"name\": \"summary\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"hgb\",\n          \"linear_svm_calibrated\",\n          \"xgb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_pr_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36191774884550276,\n        \"min\": 0.20285476737115535,\n        \"max\": 0.9102206226040714,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8715257491105368,\n          0.20285476737115535,\n          0.858232699682632\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0572430291191232,\n        \"min\": 0.8819211497219648,\n        \"max\": 0.9895668878720576,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9854620122228098,\n          0.883684952572728,\n          0.9867896518221153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3551384182153934,\n        \"min\": 0.02535852961186046,\n        \"max\": 0.9242023529166231,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6798008880773062,\n          0.02535852961186046,\n          0.8506839275360107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision@thr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4697600679062465,\n        \"min\": 0.10558872185859165,\n        \"max\": 0.9945799457994574,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9780292942743003,\n          0.1065032987747408,\n          0.9130974549968959\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall@thr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005843248432211365,\n        \"min\": 0.7003816793893127,\n        \"max\": 0.7018129770992363,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7003816793893127,\n          0.7008587786259539,\n          0.7018129770992363\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_alert_rate@thr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.059078804762793084,\n        \"min\": 0.012923675016855063,\n        \"max\": 0.12173296325158263,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.013151327828805086,\n          0.12076981673948638,\n          0.014105718463518636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_fp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6747,\n        \"min\": 8,\n        \"max\": 12435,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          33,\n          12324,\n          140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_fn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 625,\n        \"max\": 628,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          628,\n          627,\n          625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"check_alert_rate@thr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05968180212573177,\n        \"min\": 2.3965872597421273e-05,\n        \"max\": 0.11002732109476106,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.00034151368451325315,\n          0.10863730048411063,\n          0.0007549249868187701\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"check_pos_cnt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "좋아. 큰 틀에서 계산 로직이 “깨졌다”거나 결과가 불가능한 형태는 아니고, 지금 출력은 운영형 Stage1 스크리닝 관점에서 해석 가능한 상태야.\n",
        "다만 “이상하게 좋은” 수치가 몇 개 있고, 그건 데이터/피처 누수(leakage) 또는 평가 설계 착시 가능성이 있어서 확인해야 할 체크포인트가 명확히 있다. 아래에 (A) 잘못/위험 신호 점검 → (B) 결과 해석 순서로 정리한다.\n",
        "\n",
        "A. “잘못된 부분 없는지” 점검 (핵심 리스크 5개)\n",
        "1) CHECK에서 check_pos_cnt = 0 (사기 1이 없음)\n",
        "\n",
        "출력상 check는 fraud=1이 0건이야.\n",
        "\n",
        "그래서 check에서 precision/recall이 0으로 찍히는 건 정상이고, **check는 성능 평가용이 아니라 “경보율(alert_rate) 모니터링용”**으로만 의미가 있어.\n",
        "\n",
        "✅ 결론: 이건 오류가 아니라 데이터 특성.\n",
        "⚠️ 단, check로 “드리프트/운영부담”만 봐야 한다.\n",
        "\n",
        "2) LGBM/HGB가 precision≈0.99인데 FP=8~33 (너무 좋음)\n",
        "\n",
        "LGBM: recall≈0.700, TP=1468, FP=8 → precision 0.994\n",
        "\n",
        "HGB: recall≈0.701, TP=1469, FP=33 → precision 0.978\n",
        "\n",
        "이게 “절대 불가능”은 아니지만, 현실 사기탐지에서는 매우 비정상적으로 좋다고 보는 게 맞다.\n",
        "보통 이런 급의 성능은 아래 중 하나일 때 나온다:\n",
        "\n",
        "(a) 테스트셋이 “쉽게 구분되는” 분포 (사기 패턴이 너무 분리됨)\n",
        "\n",
        "(b) 피처 누수(레이블/미래정보가 피처에 섞임)\n",
        "\n",
        "(c) 전처리/평가에서 train과 test가 섞임 (time split 깨짐, join 문제 등)\n",
        "\n",
        "✅ 지금 당장 해야 할 1차 검증:\n",
        "\n",
        "타깃 컬럼/파생 피처에 fraud, label, is_fraud, chargeback, dispute 류가 포함돼 있는지\n",
        "\n",
        "시간 파생이 “미래”를 보고 만든 rolling feature인지 (예: 하루 단위 집계가 미래 거래 포함)\n",
        "\n",
        "train/test/check가 서로 겹치는 key(거래ID 등)로 중복이 있는지\n",
        "\n",
        "이 부분을 확인하지 않고 “모델이 압도적으로 좋다”라고 결론 내리면, 강사 질문에 바로 털린다.\n",
        "\n",
        "3) Logit/SVM의 alert_rate가 0.12인데 트리들은 0.013대\n",
        "\n",
        "logit: alert_rate≈0.122, precision≈0.106\n",
        "\n",
        "svm: alert_rate≈0.121, precision≈0.106\n",
        "\n",
        "hgb/lgbm: alert_rate≈0.013, precision≈0.98~0.99\n",
        "\n",
        "같은 Recall constraint(≈0.70)를 만족시키면서 경보율이 10배 차이 나는 건, 트리 모델이 훨씬 “선별”을 잘 했다는 뜻이기도 하지만, 동시에 위 2)처럼 누수 의심을 더 키우는 신호야.\n",
        "\n",
        "✅ 결론: 로직 자체는 정상이나, 데이터/피처가 너무 강한 신호를 갖고 있을 가능성이 커서 검증 필요.\n",
        "\n",
        "4) LGBM 경고: “X does not have valid feature names…”\n",
        "\n",
        "이건 scikit-learn wrapper에서 흔한 경고.\n",
        "\n",
        "전처리 결과가 numpy/희소행렬로 변하면서 feature name이 사라져서 뜨는 메시지.\n",
        "\n",
        "✅ 결론: 치명적 오류 아님. 결과는 유효.\n",
        "\n",
        "5) Threshold 값들이 “극단적으로 큼/작음”은 정상\n",
        "\n",
        "logit thr≈0.664\n",
        "\n",
        "lgbm thr≈0.924\n",
        "\n",
        "svm thr≈0.025\n",
        "\n",
        "너희 정책이 “Recall≥0.70 만족하는 구간 중 Precision 최대”라서, 모델별 score scale이 달라 threshold는 비교 대상이 아니다.\n",
        "비교는 PR-AUC/ROC-AUC/alert_rate/FP/FN로 한다.\n",
        "\n",
        "✅ 결론: threshold 자체가 이상한 건 아님.\n",
        "\n",
        "B. 결과 해석 (Stage1 운영 관점)\n",
        "1) 성능 요약(테스트 기준)\n",
        "\n",
        "표가 말하는 결론은 명확함:\n",
        "\n",
        "1등: LGBM\n",
        "\n",
        "PR-AUC 0.910, ROC-AUC 0.990\n",
        "\n",
        "Recall≈0.700 유지하면서 FP=8, Alert rate≈1.29%\n",
        "\n",
        "운영적으로 “조사량 적고 놓침도 제한”이라 최상\n",
        "\n",
        "2등: HGB\n",
        "\n",
        "PR-AUC 0.872, ROC-AUC 0.985\n",
        "\n",
        "FP=33, Alert rate≈1.32%\n",
        "\n",
        "LGBM보다 약간 거칠지만 여전히 매우 강함\n",
        "\n",
        "3등: XGB\n",
        "\n",
        "PR-AUC 0.858, ROC-AUC 0.987\n",
        "\n",
        "FP=140, Alert rate≈1.41%\n",
        "\n",
        "트리 중에선 FP가 상대적으로 큼\n",
        "\n",
        "하위: Logistic / Calibrated SVM\n",
        "\n",
        "PR-AUC 0.23/0.20대로 낮고,\n",
        "\n",
        "Recall≈0.70 맞추려면 alert_rate가 12%대로 터짐(=운영부담 큼)\n",
        "\n",
        "즉 Stage1 스크리닝 정책에는 부적합(이 데이터/피처 기준)\n",
        "\n",
        "2) check 해석(중요)\n",
        "\n",
        "check는 fraud가 0이라 성능을 논할 수 없고,\n",
        "\n",
        "LGBM check_alert_rate ≈ 0.000024 (0.0024%)\n",
        "\n",
        "HGB ≈ 0.000342\n",
        "\n",
        "XGB ≈ 0.000755\n",
        "\n",
        "Logit/SVM은 0.11대\n",
        "\n",
        "여기서 의미는:\n",
        "\n",
        "트리 모델은 check 구간에서 거의 경보를 안 울림 → 운영부담 거의 없음\n",
        "\n",
        "반면 logit/svm은 check에서 11% 경보 → 운영에서 바로 장애 수준\n",
        "\n",
        "다만! check에 fraud가 0이면 “조용한 게 좋은지” 판단이 어렵다.\n",
        "\n",
        "실제로 fraud가 없어 조용한 걸 수도 있고,\n",
        "\n",
        "분포가 바뀌어서 점수가 내려가 조용한 걸 수도 있다.\n",
        "\n",
        "그래서 check는 다음을 같이 봐야 한다:\n",
        "\n",
        "score 분포(평균/상위 1% 분위) 변화\n",
        "\n",
        "alert_rate의 시간별 추세\n",
        "\n",
        "결론: “잘못은 없지만, 너무 좋아서 검증이 필요”\n",
        "\n",
        "계산/출력은 정상.\n",
        "\n",
        "하지만 LGBM/HGB 성능이 너무 강력해서 ‘피처 누수/분할/중복’ 검증 없이 발표하면 위험.\n",
        "\n",
        "너한테 바로 필요한 “필수 검증 3종 세트” (다음 셀로 실행 권장)\n",
        "\n",
        "label 누수 컬럼 탐지\n",
        "\n",
        "컬럼명에 fraud|label|target|chargeback|dispute|cbk|refund_after 같은 패턴 포함 여부\n",
        "\n",
        "train/test/check 중복 검사\n",
        "\n",
        "transaction_id 같은 키가 있으면 split 간 중복 row 존재 여부\n",
        "\n",
        "시간 누수 검사\n",
        "\n",
        "rolling/window 파생이 “현재 시점 이후 거래”를 포함해 계산됐는지(가능하면 생성 코드/정의 확인)\n",
        "\n",
        "원하면, 너가 쓰는 데이터 컬럼 이름 기준으로 위 3개를 바로 찍는 진단 코드를 “셀 1개짜리”로 만들어 줄게."
      ],
      "metadata": {
        "id": "Vk6n4HHUsJlS"
      }
    }
  ]
}